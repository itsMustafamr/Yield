{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5c329cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabpfn import TabPFNRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# 1. Load\n",
    "train = pd.read_csv('train.csv')\n",
    "val   = pd.read_csv('val.csv')\n",
    "test  = pd.read_csv('test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d640cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Compute fill‐values on TRAIN only\n",
    "mg_mode      = train['MG'].mode()[0]           # mode for categorical MG\n",
    "lon_median   = train['Longitude'].median()     # median for longitude\n",
    "mean_cols    = ['Lodging','PlantHeight','SeedSize','Protein','Oil']\n",
    "mean_values  = train[mean_cols].mean()         # means for plant characteristics\n",
    "\n",
    "# 2. Fill missing in train/val/test\n",
    "for df in (train, val, test):\n",
    "    df['MG']        = df['MG'].fillna(mg_mode)\n",
    "    df['Longitude'] = df['Longitude'].fillna(lon_median)\n",
    "    for col in mean_cols:\n",
    "        df[col]     = df[col].fillna(mean_values[col])\n",
    "\n",
    "# 3. Define your features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9cff695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure these are defined at top‐level:\n",
    "temporal_feats = ['MaxTemp','MinTemp','AvgTemp','AvgHumidity','Precipitation','Radiation']\n",
    "static_feats   = ['Latitude','Longitude','Row.Spacing']\n",
    "plant_feats    = ['Lodging','PlantHeight','SeedSize','Protein','Oil']\n",
    "cluster_feats  = [f'Cluster_{i}' for i in range(40)]\n",
    "\n",
    "def aggregate_sequences(df, target='Yield', agg_target='mean'):\n",
    "    agg_dict = {}\n",
    "\n",
    "    # 1. temporal: mean & std\n",
    "    for feat in temporal_feats:\n",
    "        agg_dict[f'{feat}_mean'] = (feat, 'mean')\n",
    "        agg_dict[f'{feat}_std']  = (feat, 'std')\n",
    "\n",
    "    # 2. static geography: take first (constant per sequence)\n",
    "    for feat in static_feats:\n",
    "        agg_dict[feat] = (feat, 'first')\n",
    "\n",
    "    # 3. plant features:\n",
    "    #    - MG (categorical) → mode  \n",
    "    agg_dict['MG'] = ('MG', lambda x: x.mode().iloc[0])\n",
    "    #    - Lodging, PlantHeight, SeedSize, Protein, Oil → first\n",
    "    for feat in plant_feats:\n",
    "        agg_dict[feat] = (feat, 'first')\n",
    "\n",
    "    # 4. cluster indicators: proportion of time in each cluster + variability\n",
    "    for feat in cluster_feats:\n",
    "        agg_dict[f'{feat}_mean'] = (feat, 'mean')\n",
    "        agg_dict[f'{feat}_std']  = (feat, 'std')\n",
    "\n",
    "    # 5. target: mean or final\n",
    "    if agg_target == 'mean':\n",
    "        agg_dict[target] = (target, 'mean')\n",
    "    elif agg_target == 'final':\n",
    "        agg_dict[target] = (target, lambda x: x.iloc[-1])\n",
    "    else:\n",
    "        raise ValueError(\"agg_target must be 'mean' or 'final'\")\n",
    "\n",
    "    # apply the aggregation\n",
    "    grouped = df.groupby('TimeSeriesLabel').agg(**agg_dict)\n",
    "    return grouped.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5328579e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_agg = aggregate_sequences(train, agg_target='mean')\n",
    "val_agg   = aggregate_sequences(val,   agg_target='mean')\n",
    "test_agg  = aggregate_sequences(test,  agg_target='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6581624a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Split features / target\n",
    "X_train = train_agg.drop('Yield', axis=1)\n",
    "y_train = train_agg['Yield']\n",
    "X_val   = val_agg.drop('Yield',   axis=1)\n",
    "y_val   = val_agg['Yield']\n",
    "X_test  = test_agg.drop('Yield',  axis=1)\n",
    "y_test  = test_agg['Yield']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9e9fbf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train MSE: 2588.76693 | Val RMSE: 50.7239\n",
      "Epoch 010 | Train MSE: 86.89405 | Val RMSE: 8.5867\n",
      "Epoch 020 | Train MSE: 67.00433 | Val RMSE: 7.4442\n",
      "Epoch 030 | Train MSE: 59.57152 | Val RMSE: 7.0438\n",
      "Epoch 040 | Train MSE: 55.08892 | Val RMSE: 6.8310\n",
      "Epoch 050 | Train MSE: 52.29147 | Val RMSE: 6.7542\n",
      "Epoch 060 | Train MSE: 50.48360 | Val RMSE: 6.6373\n",
      "Epoch 070 | Train MSE: 49.22202 | Val RMSE: 6.5701\n",
      "Epoch 080 | Train MSE: 47.58975 | Val RMSE: 6.5068\n",
      "Epoch 090 | Train MSE: 45.49518 | Val RMSE: 6.4167\n",
      "Epoch 100 | Train MSE: 44.36301 | Val RMSE: 6.3782\n",
      "Epoch 110 | Train MSE: 43.89861 | Val RMSE: 6.3323\n",
      "Epoch 120 | Train MSE: 43.55989 | Val RMSE: 6.3414\n",
      "Epoch 130 | Train MSE: 42.03292 | Val RMSE: 6.3131\n",
      "Epoch 140 | Train MSE: 41.77255 | Val RMSE: 6.3085\n",
      "Epoch 150 | Train MSE: 41.10797 | Val RMSE: 6.2908\n",
      "Epoch 160 | Train MSE: 40.82531 | Val RMSE: 6.2904\n",
      "Epoch 170 | Train MSE: 40.95342 | Val RMSE: 6.2910\n",
      "Early stopping at epoch 172. Best Val RMSE: 6.2835\n",
      "MLP  Val R²  : 0.8243\n",
      "MLP  Val RMSE: 6.2835\n",
      "MLP  Test R² : 0.8277\n",
      "MLP  Test RMSE:6.1796\n"
     ]
    }
   ],
   "source": [
    "# %% [MLP baseline: PyTorch, early stopping, proper preprocessing]\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "# ---------- 1) Preprocess (fit on TRAIN only) ----------\n",
    "num_sel = make_column_selector(dtype_include=np.number)\n",
    "cat_sel = make_column_selector(dtype_exclude=np.number)\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), num_sel),\n",
    "    (\"cat\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1), cat_sel),\n",
    "], remainder=\"drop\")\n",
    "\n",
    "pre.fit(X_train)\n",
    "\n",
    "Xtr = pre.transform(X_train).astype(np.float32)\n",
    "Xva = pre.transform(X_val).astype(np.float32)\n",
    "Xte = pre.transform(X_test).astype(np.float32)\n",
    "\n",
    "ytr = y_train.to_numpy(dtype=np.float32).reshape(-1, 1)\n",
    "yva = y_val.to_numpy(dtype=np.float32).reshape(-1, 1)\n",
    "yte = y_test.to_numpy(dtype=np.float32).reshape(-1, 1)\n",
    "\n",
    "# ---------- 2) DataLoaders ----------\n",
    "BATCH_SIZE = 1024\n",
    "train_loader = DataLoader(TensorDataset(torch.from_numpy(Xtr), torch.from_numpy(ytr)),\n",
    "                          batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "val_loader   = DataLoader(TensorDataset(torch.from_numpy(Xva), torch.from_numpy(yva)),\n",
    "                          batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "test_tensorX = torch.from_numpy(Xte)\n",
    "test_tensory = torch.from_numpy(yte)\n",
    "\n",
    "# ---------- 3) Model ----------\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, 256), nn.ReLU(),\n",
    "            nn.BatchNorm1d(256), nn.Dropout(0.2),\n",
    "            nn.Linear(256, 256), nn.ReLU(),\n",
    "            nn.BatchNorm1d(256), nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128), nn.ReLU(),\n",
    "            nn.BatchNorm1d(128), nn.Dropout(0.1),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MLP(in_dim=Xtr.shape[1]).to(device)\n",
    "\n",
    "# ---------- 4) Train loop (early stopping on Val RMSE) ----------\n",
    "EPOCHS = 200\n",
    "PATIENCE = 20\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=5)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "best_val = float(\"inf\")\n",
    "best_state = None\n",
    "no_improve = 0\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    # train\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        xb = xb.to(device); yb = yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(xb)\n",
    "        loss = loss_fn(pred, yb)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * xb.size(0)\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # validate\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        va_preds = []\n",
    "        va_targets = []\n",
    "        for xb, yb in val_loader:\n",
    "            xb = xb.to(device)\n",
    "            pred = model(xb).cpu().numpy().ravel()\n",
    "            va_preds.append(pred)\n",
    "            va_targets.append(yb.numpy().ravel())\n",
    "        va_preds = np.concatenate(va_preds)\n",
    "        va_targets = np.concatenate(va_targets)\n",
    "        va_rmse = rmse(va_targets, va_preds)\n",
    "\n",
    "    scheduler.step(va_rmse)\n",
    "\n",
    "    if va_rmse < best_val - 1e-6:\n",
    "        best_val = va_rmse\n",
    "        best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "        no_improve = 0\n",
    "    else:\n",
    "        no_improve += 1\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == 1:\n",
    "        print(f\"Epoch {epoch:03d} | Train MSE: {train_loss:.5f} | Val RMSE: {va_rmse:.4f}\")\n",
    "\n",
    "    if no_improve >= PATIENCE:\n",
    "        print(f\"Early stopping at epoch {epoch}. Best Val RMSE: {best_val:.4f}\")\n",
    "        break\n",
    "\n",
    "# restore best weights\n",
    "if best_state is not None:\n",
    "    model.load_state_dict({k: v.to(device) for k, v in best_state.items()})\n",
    "\n",
    "# ---------- 5) Final eval on Val/Test ----------\n",
    "def predict_torch(net, X):\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = net(X.to(device)).cpu().numpy().ravel()\n",
    "    return preds\n",
    "\n",
    "val_preds  = predict_torch(model, torch.from_numpy(Xva))\n",
    "test_preds = predict_torch(model, test_tensorX)\n",
    "\n",
    "print(f\"MLP  Val R²  : {r2_score(yva.ravel(),  val_preds):.4f}\")\n",
    "print(f\"MLP  Val RMSE: {rmse(yva.ravel(),      val_preds):.4f}\")\n",
    "print(f\"MLP  Test R² : {r2_score(yte.ravel(),  test_preds):.4f}\")\n",
    "print(f\"MLP  Test RMSE:{rmse(yte.ravel(),      test_preds):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c696b9e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabpfn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
