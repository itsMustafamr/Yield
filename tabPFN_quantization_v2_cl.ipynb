{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4475e73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabpfn import TabPFNRegressor\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error\n",
    "\n",
    "# %%\n",
    "# 1. Load your datasets\n",
    "train = pd.read_csv('train.csv')\n",
    "val   = pd.read_csv('val.csv')\n",
    "test  = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cbee09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Inspect shapes and columns\n",
    "for name, df in {'train': train, 'val': val, 'test': test}.items():\n",
    "    print(f\"\\n=== {name.upper()} ===\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(\"Columns:\", list(df.columns))\n",
    "\n",
    "# %%\n",
    "# 3. Check for missing values\n",
    "for name, df in {'train': train, 'val': val, 'test': test}.items():\n",
    "    missing = df.isnull().sum()\n",
    "    print(f\"\\n{name.upper()} missing values per column:\")\n",
    "    print(missing[missing > 0] if missing.any() else \"No missing values!\")\n",
    "\n",
    "# %% [markdown]\n",
    "# # Data Preprocessing\n",
    "\n",
    "# %%\n",
    "# 1. Compute fill‐values on TRAIN only\n",
    "mg_mode      = train['MG'].mode()[0]           # mode for categorical MG\n",
    "lon_median   = train['Longitude'].median()     # median for longitude\n",
    "mean_cols    = ['Lodging','PlantHeight','SeedSize','Protein','Oil']\n",
    "mean_values  = train[mean_cols].mean()         # means for plant characteristics\n",
    "\n",
    "# 2. Fill missing in train/val/test\n",
    "for df in (train, val, test):\n",
    "    df['MG']        = df['MG'].fillna(mg_mode)\n",
    "    df['Longitude'] = df['Longitude'].fillna(lon_median)\n",
    "    for col in mean_cols:\n",
    "        df[col]     = df[col].fillna(mean_values[col])\n",
    "\n",
    "# 3. Verify no missing remain in those columns\n",
    "for name, df in {'train': train, 'val': val, 'test': test}.items():\n",
    "    rem = df[['MG','Longitude'] + mean_cols].isnull().sum()\n",
    "    print(f\"{name.upper()} remaining nulls:\\n\", rem)\n",
    "\n",
    "# 4. Define your features\n",
    "temporal_feats = ['MaxTemp','MinTemp','AvgTemp','AvgHumidity','Precipitation','Radiation']  # 6\n",
    "static_feats   = ['Latitude','Longitude','Row.Spacing']                                    # 3\n",
    "\n",
    "# %% [markdown]\n",
    "# # Sequence Aggregation\n",
    "\n",
    "# %%\n",
    "# 5. Aggregate each sequence → one row\n",
    "def aggregate_sequences(df, target='Yield', agg_target='mean'):\n",
    "    # build dict of aggregation funcs\n",
    "    agg_dict = {}\n",
    "    # temporal: mean & std\n",
    "    for feat in temporal_feats:\n",
    "        agg_dict[feat + '_mean'] = (feat, 'mean')\n",
    "        agg_dict[feat + '_std']  = (feat, 'std')\n",
    "    # static: just take first (they're constant per sequence)\n",
    "    for feat in static_feats:\n",
    "        agg_dict[feat] = (feat, 'first')\n",
    "    # target: either mean or final\n",
    "    if agg_target == 'mean':\n",
    "        agg_dict[target] = (target, 'mean')\n",
    "    elif agg_target == 'final':\n",
    "        agg_dict[target] = (target, lambda x: x.iloc[-1])\n",
    "    else:\n",
    "        raise ValueError(\"agg_target must be 'mean' or 'final'\")\n",
    "\n",
    "    grouped = df.groupby('TimeSeriesLabel').agg(**agg_dict)\n",
    "    return grouped.reset_index(drop=True)\n",
    "\n",
    "train_agg = aggregate_sequences(train, agg_target='mean')\n",
    "val_agg   = aggregate_sequences(val,   agg_target='mean')\n",
    "test_agg  = aggregate_sequences(test,  agg_target='mean')\n",
    "\n",
    "print(f\"Train aggregated shape: {train_agg.shape}\")\n",
    "print(f\"Val aggregated shape: {val_agg.shape}\")\n",
    "print(f\"Test aggregated shape: {test_agg.shape}\")\n",
    "\n",
    "# %%\n",
    "# 6. Split features / target\n",
    "X_train = train_agg.drop('Yield', axis=1)\n",
    "y_train = train_agg['Yield']\n",
    "X_val   = val_agg.drop('Yield',   axis=1)\n",
    "y_val   = val_agg['Yield']\n",
    "X_test  = test_agg.drop('Yield',  axis=1)\n",
    "y_test  = test_agg['Yield']\n",
    "\n",
    "# %% [markdown]\n",
    "# # Baseline Model (No Quantization)\n",
    "\n",
    "# %%\n",
    "# 7. Subsample 10k and fit TabPFN\n",
    "np.random.seed(42)\n",
    "train_sub = train_agg.sample(n=10_000, random_state=42)\n",
    "X_sub     = train_sub.drop('Yield', axis=1).to_numpy()\n",
    "y_sub     = train_sub['Yield'].to_numpy()\n",
    "\n",
    "model = TabPFNRegressor()\n",
    "model.fit(X_sub, y_sub)\n",
    "\n",
    "# 8. Evaluate on full val/test sets\n",
    "print(\"=== BASELINE RESULTS (No Quantization) ===\")\n",
    "for name, X_np, y_np in [\n",
    "        ('Val',  X_val.to_numpy(),  y_val.to_numpy()),\n",
    "        ('Test', X_test.to_numpy(), y_test.to_numpy())\n",
    "    ]:\n",
    "    preds = model.predict(X_np)\n",
    "    print(f\"{name} R²   : {r2_score(y_np, preds):.4f}\")\n",
    "    print(f\"{name} RMSE : {root_mean_squared_error(y_np, preds):.4f}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# # Quantization Helper\n",
    "\n",
    "# %%\n",
    "def quantize_df(df: pd.DataFrame, b: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Quantize each column in df to 2^b levels between min and max.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame to quantize\n",
    "        b: Number of bits (2^b levels)\n",
    "    \n",
    "    Returns:\n",
    "        Quantized DataFrame\n",
    "    \"\"\"\n",
    "    df_q = df.copy()\n",
    "    levels = 2 ** b\n",
    "    \n",
    "    for col in df_q.columns:\n",
    "        xmin, xmax = df_q[col].min(), df_q[col].max()\n",
    "        # if constant column, skip\n",
    "        if xmax == xmin:\n",
    "            continue\n",
    "        delta = (xmax - xmin) / (levels - 1)\n",
    "        df_q[col] = xmin + delta * np.round((df_q[col] - xmin) / delta)\n",
    "    \n",
    "    return df_q\n",
    "\n",
    "# %% [markdown]\n",
    "# # Apply Quantization with Different Bit Levels\n",
    "\n",
    "# %%\n",
    "# Store results for comparison\n",
    "results = {\n",
    "    'baseline': {\n",
    "        'val_r2': r2_score(y_val.to_numpy(), model.predict(X_val.to_numpy())),\n",
    "        'val_rmse': root_mean_squared_error(y_val.to_numpy(), model.predict(X_val.to_numpy())),\n",
    "        'test_r2': r2_score(y_test.to_numpy(), model.predict(X_test.to_numpy())),\n",
    "        'test_rmse': root_mean_squared_error(y_test.to_numpy(), model.predict(X_test.to_numpy()))\n",
    "    }\n",
    "}\n",
    "\n",
    "# Try different quantization levels\n",
    "for b in [7, 8]:  # 8, 16, 32, 64, 128, 256 levels\n",
    "    print(f\"\\n=== QUANTIZATION with b={b} ({2**b} levels) ===\")\n",
    "    \n",
    "    # Convert numpy arrays back to DataFrames for quantization\n",
    "    X_sub_df = pd.DataFrame(X_sub, columns=X_train.columns)\n",
    "    X_val_df = pd.DataFrame(X_val.to_numpy(), columns=X_val.columns)\n",
    "    X_test_df = pd.DataFrame(X_test.to_numpy(), columns=X_test.columns)\n",
    "    \n",
    "    # Quantize training subset\n",
    "    X_sub_q = quantize_df(X_sub_df, b).to_numpy()\n",
    "    \n",
    "    # Fit model on quantized data\n",
    "    model_q = TabPFNRegressor()\n",
    "    model_q.fit(X_sub_q, y_sub)\n",
    "    \n",
    "    # Quantize and evaluate validation/test\n",
    "    X_val_q = quantize_df(X_val_df, b).to_numpy()\n",
    "    X_test_q = quantize_df(X_test_df, b).to_numpy()\n",
    "    \n",
    "    # Store results\n",
    "    results[f'b={b}'] = {}\n",
    "    \n",
    "    for name, X_q, y in [('val', X_val_q, y_val.to_numpy()), \n",
    "                         ('test', X_test_q, y_test.to_numpy())]:\n",
    "        preds = model_q.predict(X_q)\n",
    "        r2 = r2_score(y, preds)\n",
    "        rmse = root_mean_squared_error(y, preds)\n",
    "        \n",
    "        results[f'b={b}'][f'{name}_r2'] = r2\n",
    "        results[f'b={b}'][f'{name}_rmse'] = rmse\n",
    "        \n",
    "        print(f\"{name.upper()} R²: {r2:.4f}, RMSE: {rmse:.4f}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# # Results Summary\n",
    "\n",
    "# %%\n",
    "# Create summary DataFrame\n",
    "summary_data = []\n",
    "for method, metrics in results.items():\n",
    "    summary_data.append({\n",
    "        'Method': method,\n",
    "        'Val R²': metrics['val_r2'],\n",
    "        'Val RMSE': metrics['val_rmse'],\n",
    "        'Test R²': metrics['test_r2'],\n",
    "        'Test RMSE': metrics['test_rmse']\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"\\n=== RESULTS SUMMARY ===\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Find best quantization level\n",
    "best_val_r2_idx = summary_df['Val R²'].idxmax()\n",
    "print(f\"\\nBest validation R²: {summary_df.iloc[best_val_r2_idx]['Method']}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# # Visualize Quantization Effect\n",
    "\n",
    "# %%\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot R² scores\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "methods = summary_df['Method'].values\n",
    "val_r2 = summary_df['Val R²'].values\n",
    "test_r2 = summary_df['Test R²'].values\n",
    "\n",
    "ax1.plot(methods, val_r2, 'bo-', label='Validation')\n",
    "ax1.plot(methods, test_r2, 'ro-', label='Test')\n",
    "ax1.set_xlabel('Quantization Method')\n",
    "ax1.set_ylabel('R² Score')\n",
    "ax1.set_title('R² Score vs Quantization Level')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xticklabels(methods, rotation=45)\n",
    "\n",
    "# Plot RMSE scores\n",
    "val_rmse = summary_df['Val RMSE'].values\n",
    "test_rmse = summary_df['Test RMSE'].values\n",
    "\n",
    "ax2.plot(methods, val_rmse, 'bo-', label='Validation')\n",
    "ax2.plot(methods, test_rmse, 'ro-', label='Test')\n",
    "ax2.set_xlabel('Quantization Method')\n",
    "ax2.set_ylabel('RMSE')\n",
    "ax2.set_title('RMSE vs Quantization Level')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_xticklabels(methods, rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# Optional: Examine quantization effect on a single feature\n",
    "feature_to_examine = 'MaxTemp_mean'\n",
    "if feature_to_examine in X_train.columns:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    original_values = X_train[feature_to_examine].values[:1000]  # First 1000 samples\n",
    "    \n",
    "    for i, b in enumerate([3, 4, 5, 6, 7, 8]):\n",
    "        ax = axes[i]\n",
    "        quantized_values = quantize_df(pd.DataFrame({feature_to_examine: original_values}), b)[feature_to_examine].values\n",
    "        \n",
    "        ax.scatter(original_values, quantized_values, alpha=0.5, s=1)\n",
    "        ax.plot([original_values.min(), original_values.max()], \n",
    "                [original_values.min(), original_values.max()], \n",
    "                'r--', label='y=x')\n",
    "        ax.set_xlabel('Original Values')\n",
    "        ax.set_ylabel('Quantized Values')\n",
    "        ax.set_title(f'b={b} ({2**b} levels)')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle(f'Quantization Effect on {feature_to_examine}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
